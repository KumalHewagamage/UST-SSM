{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa39b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.humanml import HumanML3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc074fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HumanML3D(root='data/v4.3-wall-humanML3d-2136', frames_per_clip=16, num_points=2048, train=True)\n",
    "test_dataset = HumanML3D(root='data/v4.3-wall-humanML3d-2136', frames_per_clip=16, num_points=2048, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e57427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 23008\n",
      "Test dataset size: 4314\n"
     ]
    }
   ],
   "source": [
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996415ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data sample shape: (16, 2048, 3)\n",
      "Test data sample shape: (16, 2048, 3)\n",
      "Train data sample caption: a man squats extraordinarily low then bolts up in an unsatisfactory jump\n",
      "Test data sample caption: a man kicks something or someone with his left leg\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset[0]\n",
    "test_data = test_dataset[0]\n",
    "print(f'Train data sample shape: {train_data[0].shape}')\n",
    "print(f'Test data sample shape: {test_data[0].shape}')\n",
    "print(f'Train data sample caption: {train_data[1]}')\n",
    "print(f'Test data sample caption: {test_data[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c86227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ac399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.humanml_seg import HumanML3D\n",
    "\n",
    "train_dataset = HumanML3D(root='data/v4.3-wall-humanML3d-2136', frames_per_clip=16, num_points=2048, train=True)\n",
    "test_dataset = HumanML3D(root='data/v4.3-wall-humanML3d-2136', frames_per_clip=16, num_points=2048, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d13339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points shape: (16, 2048, 3)\n",
      "Segmentation shape: (16, 2048)\n",
      "Caption: a person falls to the ground in a sitting motion and then pops back up in a standing position\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset[0]\n",
    "print(f'Points shape: {train_data[0].shape}')\n",
    "print(f'Segmentation shape: {train_data[1].shape}')\n",
    "print(f'Caption: {train_data[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import sys \n",
    "import os\n",
    "\n",
    "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# ROOT_DIR = os.path.dirname(BASE_DIR)\n",
    "# sys.path.append(ROOT_DIR)\n",
    "# sys.path.append(os.path.join(ROOT_DIR, 'modules'))\n",
    "\n",
    "from modules.point_4d_convolution import *\n",
    "\n",
    "import math\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.models.layers import DropPath\n",
    "from functools import partial\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from mamba_ssm.modules.mamba_simple import Mamba\n",
    "\n",
    "try:\n",
    "    from mamba_ssm.ops.triton.layernorm import RMSNorm, layer_norm_fn, rms_norm_fn\n",
    "except ImportError:\n",
    "    RMSNorm, layer_norm_fn, rms_norm_fn = None, None, None\n",
    "\n",
    "from models.block import Block\n",
    "from models.Curve import *\n",
    "from ipdb import set_trace as st\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "def _init_weights(\n",
    "        module,\n",
    "        n_layer,\n",
    "        initializer_range=0.02,  \n",
    "        rescale_prenorm_residual=True,\n",
    "        n_residuals_per_layer=1,  \n",
    "):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        if module.bias is not None:\n",
    "            if not getattr(module.bias, \"_no_reinit\", False):\n",
    "                nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        nn.init.normal_(module.weight, std=initializer_range)\n",
    "\n",
    "    if rescale_prenorm_residual:\n",
    "        for name, p in module.named_parameters():\n",
    "            if name in [\"out_proj.weight\", \"fc2.weight\"]:\n",
    "                nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                with torch.no_grad():\n",
    "                    p /= math.sqrt(n_residuals_per_layer * n_layer)\n",
    "\n",
    "\n",
    "def create_block(\n",
    "        d_model,\n",
    "        ssm_cfg=None,\n",
    "        norm_epsilon=1e-5,\n",
    "        rms_norm=False,\n",
    "        residual_in_fp32=False,\n",
    "        fused_add_norm=False,\n",
    "        layer_idx=None,\n",
    "        drop_path=0.,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "):\n",
    "    if ssm_cfg is None:\n",
    "        ssm_cfg = {}\n",
    "    factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "    mixer_cls = partial(Mamba, layer_idx=layer_idx, **ssm_cfg, **factory_kwargs)\n",
    "    norm_cls = partial(\n",
    "        nn.LayerNorm if not rms_norm else RMSNorm, eps=norm_epsilon, **factory_kwargs\n",
    "    )\n",
    "    block = Block(\n",
    "        d_model,\n",
    "        mixer_cls,\n",
    "        norm_cls=norm_cls,\n",
    "        fused_add_norm=fused_add_norm,\n",
    "        residual_in_fp32=residual_in_fp32,\n",
    "        drop_path=drop_path,\n",
    "    )\n",
    "    block.layer_idx = layer_idx\n",
    "    return block\n",
    "\n",
    "\n",
    "class UST(nn.Module):\n",
    "    def __init__(self, radius, nsamples, spatial_stride,                               \n",
    "                 temporal_kernel_size, temporal_stride,                                 \n",
    "                 dim, depth, heads,                               \n",
    "                 mlp_dim, num_classes, dropout, hos_branches_num, encoder_channel):                         \n",
    "        super().__init__()\n",
    "        self.hos_branches_num = hos_branches_num\n",
    "        self.depth = depth\n",
    "\n",
    "        self.inner = 32\n",
    "        self.tokens = 64\n",
    "        self.hidden = 1\n",
    "\n",
    "\n",
    "        self.tube_embedding = P4DConv(in_planes=0, mlp_planes=[dim//2], mlp_batch_norm=[False], mlp_activation=[False],\n",
    "                                  spatial_kernel_size=[radius, nsamples], spatial_stride=spatial_stride//8,\n",
    "                                  temporal_kernel_size=temporal_kernel_size, temporal_stride=1, temporal_padding=[0, 0],\n",
    "                                  operator='+', spatial_pooling='max', temporal_pooling='max')\n",
    "        self.tube_embedding1 = P4DConv(in_planes=dim//2, mlp_planes=[dim], mlp_batch_norm=[False], mlp_activation=[False],\n",
    "                                  spatial_kernel_size=[radius, nsamples], spatial_stride=spatial_stride//4,\n",
    "                                  temporal_kernel_size=temporal_kernel_size, temporal_stride=temporal_stride, temporal_padding=[1, 0],\n",
    "                                  operator='+', spatial_pooling='max', temporal_pooling='max')\n",
    "\n",
    "        self.pos_embed = nn.Sequential(\n",
    "            nn.Linear(4, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, dim + self.hidden)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self.ssm_blocks = nn.ModuleList()\n",
    "        initial_k_group_size = 12\n",
    "        for i in range(self.hos_branches_num):\n",
    "            branch_ssm_blocks = nn.ModuleList()\n",
    "            for _ in range(self.depth):\n",
    "                k_group_size = max(1, initial_k_group_size // (2 ** i))\n",
    "                ssm_block = AggregationSSM(\n",
    "                    dim=dim + self.hidden,\n",
    "                    num_group=768,\n",
    "                    num_heads=heads,\n",
    "                    drop_path=0.1,\n",
    "                    k_group_size=k_group_size,\n",
    "                )\n",
    "                branch_ssm_blocks.append(ssm_block)\n",
    "            self.ssm_blocks.append(branch_ssm_blocks)\n",
    "\n",
    "\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(self.hos_branches_num * (dim+self.hidden) ),\n",
    "            nn.Linear(self.hos_branches_num * (dim+self.hidden), mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self.route = nn.Sequential(\n",
    "         PointNet(dim,self.tokens),\n",
    "         nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.embeddingB = nn.Embedding(self.tokens, self.inner) \n",
    "        self.embeddingB.weight.data.uniform_(-1 / self.tokens, 1 / self.tokens)\n",
    "\n",
    "        self.token1 = nn.Embedding(self.inner, self.hidden)\n",
    "        self.token1.weight.data.uniform_(-1 / self.inner, 1 / self.inner)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        device = input.get_device()\n",
    "        xyzs, features = self.tube_embedding(input) \n",
    "        print('after first tube embedding, xyzs shape:', xyzs.shape)\n",
    "        print('after first tube embedding, features shape:', features.shape)\n",
    "        xyzs, features = self.tube_embedding1(xyzs, features) \n",
    "        B, L, n, _ = xyzs.shape\n",
    "        C = features.shape[2]\n",
    "\n",
    "    \n",
    "        features = features.permute(0, 1, 3, 2)\n",
    "        features = features.reshape(B, L * n, -1)\n",
    "        xyzs = xyzs.reshape(B, L * n, -1)\n",
    "      \n",
    "        pred_route = self.route(features)  \n",
    "\n",
    "        cls_policy = F.gumbel_softmax(pred_route, hard=True, dim=-1)  \n",
    "        full_embedding1 = self.embeddingB.weight @ self.token1.weight  \n",
    "\n",
    "\n",
    "        prompt = torch.matmul(cls_policy, full_embedding1).view(B, L * n, self.hidden)    \n",
    "\n",
    "        features = torch.cat([features, prompt], dim=2)\n",
    "\n",
    "\n",
    "        detached_index = torch.argmax(cls_policy.detach(), dim=-1, keepdim=False) \n",
    "        x_sort_values, x_sort_indices = torch.sort(detached_index, dim=-1, stable=False)\n",
    "\n",
    "        sorted_indices_expanded = x_sort_indices.unsqueeze(-1).expand(-1, -1, features.shape[-1]) \n",
    "        features = torch.gather(features, dim=1, index=sorted_indices_expanded)  \n",
    "\n",
    "        if xyzs is not None:\n",
    "            sorted_indices_expanded_xyz = x_sort_indices.unsqueeze(-1).expand(-1, -1, xyzs.shape[-1])\n",
    "            xyzs = torch.gather(xyzs, dim=1, index=sorted_indices_expanded_xyz)  \n",
    "\n",
    "\n",
    "\n",
    "        features = features.reshape(B, L, -1, n)\n",
    "        features = features.permute(0, 1, 3, 2)\n",
    "        xyzs = xyzs.reshape(B, L, n, -1)\n",
    " \n",
    "        xyzts = []\n",
    "        xyzs_split = torch.split(tensor=xyzs, split_size_or_sections=1, dim=1)\n",
    "        xyzs_split = [torch.squeeze(input=xyz, dim=1).contiguous() for xyz in xyzs_split]\n",
    "        for t, xyz in enumerate(xyzs_split):\n",
    "            t_val = torch.ones((xyz.size()[0], xyz.size()[1], 1), dtype=torch.float32, device=device) * (t + 1)\n",
    "            t_val = torch.div(t_val, xyzs.shape[1], rounding_mode='floor')\n",
    "            xyzt = torch.cat(tensors=(xyz, t_val), dim=2)\n",
    "            xyzts.append(xyzt)\n",
    "\n",
    "        xyzts = torch.stack(tensors=xyzts, dim=1)\n",
    "        pos = self.pos_embed(xyzts)\n",
    "\n",
    "        features = features.permute(0, 1, 3, 2)\n",
    "\n",
    "        downsampling_factors = [2 ** i for i in range(self.hos_branches_num)]\n",
    "        outputs = []\n",
    "        main_x_output = None  \n",
    "\n",
    "        for i, downsampling_factor in enumerate(downsampling_factors):\n",
    "            if downsampling_factor == 1:\n",
    "                indices = list(range(L))\n",
    "            else:\n",
    "                indices = [max(0, min(L - 1, k)) for k in range(0, L, downsampling_factor)]\n",
    "\n",
    "            xyzs_branch = xyzs[:, indices, :, :]  # [B, W, n, 3]\n",
    "            features_branch = features[:, indices, :, :]  # [B, W, C, n]\n",
    "\n",
    "\n",
    "            W = xyzs_branch.shape[1]\n",
    "\n",
    "            xyzs_branch = xyzs_branch.reshape(B, W * n, 3)\n",
    "            \n",
    "            pos_branch = pos[:, indices, :, :]\n",
    "            pos_branch = pos_branch.reshape(B, W * n, pos_branch.shape[-1])\n",
    "\n",
    "\n",
    "            features_branch = features_branch.reshape(B, W * n, C+self.hidden)\n",
    "            x_branch = features_branch + pos_branch  # [B, W*n, C]\n",
    "\n",
    "            x_output = x_branch\n",
    "    \n",
    "            for ssm_block in self.ssm_blocks[i]:\n",
    "                x_output = ssm_block(center=xyzs_branch, x=x_output)  # [B, W*n, C_out]\n",
    "\n",
    "            if downsampling_factor == 1:\n",
    "                main_x_output = x_output  # [B, L*n, C_out]\n",
    "\n",
    "            output_branch = torch.max(x_output, dim=1, keepdim=False)[0]  # [B, C_out]\n",
    "            outputs.append(output_branch)\n",
    "\n",
    "\n",
    "        feat = main_x_output.reshape(B, L, n, -1)  # [B, L, n, C_out]\n",
    "\n",
    "\n",
    "        outputs_concat = outputs# [key_output, output0, output1, output2, ...]\n",
    "        print('outputs_concat len:', len(outputs_concat))\n",
    "        print('each output shape:', [o.shape for o in outputs_concat])\n",
    "        output = torch.cat(outputs_concat, dim=1)  # [B, dim//2 + hos_branches_num * C_out]\n",
    "        print('final output shape before mlp head:', output.shape)\n",
    "\n",
    "        # output = self.mlp_head(output)  # [B, num_classes]\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super(TNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)  \n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        k = x.size(1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = torch.max(x, 2)[0]  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = x.view(batch_size, k, k)  \n",
    "        return x\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, input_channels, tokens, num_classes=None):\n",
    "        super(PointNet, self).__init__()\n",
    "        \n",
    "        self.tnet = TNet(k=input_channels)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, tokens)  \n",
    "\n",
    "        self.tokens = tokens\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.permute(0, 2,1)\n",
    "        trans = self.tnet(x)\n",
    "        x = torch.bmm(x.transpose(2, 1), trans)  \n",
    "        x = x.permute(0, 2,1)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.permute(0, 2,1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  \n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f647907",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "        'radius': 0.7, # 0.3\n",
    "        'nsamples': 32, # 32\n",
    "        'spatial_stride': 32,\n",
    "        'temporal_kernel_size': 3,\n",
    "        'temporal_stride': 2, # 2\n",
    "        'dim': 160,\n",
    "        'heads': 6,\n",
    "        'mlp_dim': 320,\n",
    "        'num_classes': 20, # Note: Check if this matches your dataset classes\n",
    "        'dropout': 0.0,\n",
    "        'depth': 1, # 1\n",
    "        'hos_branches_num': 3,\n",
    "        'encoder_channel': 60\n",
    "    }\n",
    "\n",
    "model = UST(**model_params).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "312bf741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs_concat len: 3\n",
      "each output shape: [torch.Size([5, 161]), torch.Size([5, 161]), torch.Size([5, 161])]\n",
      "final output shape before mlp head: torch.Size([5, 483])\n"
     ]
    }
   ],
   "source": [
    "from datasets.humanml_seg import HumanML3D\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = HumanML3D(root='data/v4.3-wall-humanML3d-2136', frames_per_clip=16, num_points=2048, train=True)\n",
    "test_dataset = HumanML3D(root='data/v4.3-wall-humanML3d-2136', frames_per_clip=16, num_points=2048, train=False)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=5, \n",
    "        shuffle=True, \n",
    "        num_workers=2, \n",
    "        pin_memory=True,\n",
    "        drop_last=True # Important for batch stability\n",
    "    )\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "point_data, seg_data, caption = next(data_iter)\n",
    "\n",
    "point_data = point_data.to('cuda')\n",
    "out = model(point_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
